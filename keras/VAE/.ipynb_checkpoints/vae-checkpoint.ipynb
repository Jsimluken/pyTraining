{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "'''Example of VAE on MNIST dataset using MLP\n",
    "The VAE has a modular design. The encoder, decoder and VAE\n",
    "are 3 models that share weights. After training the VAE model,\n",
    "the encoder can be used to generate latent vectors.\n",
    "The decoder can be used to generate MNIST digits by sampling the\n",
    "latent vector from a Gaussian distribution with mean = 0 and std = 1.\n",
    "# Reference\n",
    "[1] Kingma, Diederik P., and Max Welling.\n",
    "\"Auto-Encoding Variational Bayes.\"\n",
    "https://arxiv.org/abs/1312.6114\n",
    "'''\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "from keras.layers import Lambda, Input, Dense\n",
    "from keras.models import Model\n",
    "from keras.datasets import mnist\n",
    "from keras.losses import mse, binary_crossentropy\n",
    "from keras.utils import plot_model\n",
    "from keras import backend as K\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reparameterization trick\n",
    "# instead of sampling from Q(z|X), sample epsilon = N(0,I)\n",
    "# z = z_mean + sqrt(var) * epsilon\n",
    "def sampling(args):\n",
    "    \"\"\"Reparameterization trick by sampling from an isotropic unit Gaussian.\n",
    "    # Arguments\n",
    "        args (tensor): mean and log of variance of Q(z|X)\n",
    "    # Returns\n",
    "        z (tensor): sampled latent vector\n",
    "    \"\"\"\n",
    "\n",
    "    z_mean, z_log_var = args\n",
    "    batch = K.shape(z_mean)[0]\n",
    "    dim = K.int_shape(z_mean)[1]\n",
    "    # by default, random_normal has mean = 0 and std = 1.0\n",
    "    epsilon = K.random_normal(shape=(batch, dim))\n",
    "    return z_mean + K.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "\n",
    "def plot_results(models,\n",
    "                 data,\n",
    "                 batch_size=128,\n",
    "                 model_name=\"vae_mnist\"):\n",
    "    \"\"\"Plots labels and MNIST digits as a function of the 2D latent vector\n",
    "    # Arguments\n",
    "        models (tuple): encoder and decoder models\n",
    "        data (tuple): test data and label\n",
    "        batch_size (int): prediction batch size\n",
    "        model_name (string): which model is using this function\n",
    "    \"\"\"\n",
    "\n",
    "    encoder, decoder = models\n",
    "    x_test, y_test = data\n",
    "    os.makedirs(model_name, exist_ok=True)\n",
    "\n",
    "    filename = os.path.join(model_name, \"vae_mean.png\")\n",
    "    # display a 2D plot of the digit classes in the latent space\n",
    "    z_mean, _, _ = encoder.predict(x_test,\n",
    "                                   batch_size=batch_size)\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    plt.scatter(z_mean[:, 0], z_mean[:, 1], c=y_test)\n",
    "    plt.colorbar()\n",
    "    plt.xlabel(\"z[0]\")\n",
    "    plt.ylabel(\"z[1]\")\n",
    "    plt.savefig(filename)\n",
    "    plt.show()\n",
    "\n",
    "    filename = os.path.join(model_name, \"digits_over_latent.png\")\n",
    "    # display a 30x30 2D manifold of digits\n",
    "    n = 30\n",
    "    digit_size = 28\n",
    "    figure = np.zeros((digit_size * n, digit_size * n))\n",
    "    # linearly spaced coordinates corresponding to the 2D plot\n",
    "    # of digit classes in the latent space\n",
    "    grid_x = np.linspace(-4, 4, n)\n",
    "    grid_y = np.linspace(-4, 4, n)[::-1]\n",
    "\n",
    "    for i, yi in enumerate(grid_y):\n",
    "        for j, xi in enumerate(grid_x):\n",
    "            z_sample = np.array([[xi, yi]])\n",
    "            x_decoded = decoder.predict(z_sample)\n",
    "            digit = x_decoded[0].reshape(digit_size, digit_size)\n",
    "            figure[i * digit_size: (i + 1) * digit_size,\n",
    "                   j * digit_size: (j + 1) * digit_size] = digit\n",
    "\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    start_range = digit_size // 2\n",
    "    end_range = (n - 1) * digit_size + start_range + 1\n",
    "    pixel_range = np.arange(start_range, end_range, digit_size)\n",
    "    sample_range_x = np.round(grid_x, 1)\n",
    "    sample_range_y = np.round(grid_y, 1)\n",
    "    plt.xticks(pixel_range, sample_range_x)\n",
    "    plt.yticks(pixel_range, sample_range_y)\n",
    "    plt.xlabel(\"z[0]\")\n",
    "    plt.ylabel(\"z[1]\")\n",
    "    plt.imshow(figure, cmap='Greys_r')\n",
    "    plt.savefig(filename)\n",
    "    plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_input (InputLayer)      (None, 784)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 512)          401920      encoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "z_mean (Dense)                  (None, 2)            1026        dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "z_log_var (Dense)               (None, 2)            1026        dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "z (Lambda)                      (None, 2)            0           z_mean[0][0]                     \n",
      "                                                                 z_log_var[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 403,972\n",
      "Trainable params: 403,972\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "z_sampling (InputLayer)      (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 512)               1536      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 784)               402192    \n",
      "=================================================================\n",
      "Total params: 403,728\n",
      "Trainable params: 403,728\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jsimluken/.pyenv/versions/miniconda3-latest/lib/python3.6/site-packages/ipykernel_launcher.py:63: UserWarning: Output \"decoder\" missing from loss dictionary. We assume this was done on purpose, and we will not be expecting any data to be passed to \"decoder\" during training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "encoder (Model)              [(None, 2), (None, 2), (N 403972    \n",
      "_________________________________________________________________\n",
      "decoder (Model)              (None, 784)               403728    \n",
      "=================================================================\n",
      "Total params: 807,700\n",
      "Trainable params: 807,700\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 20s 329us/step - loss: 51.8313 - val_loss: 43.8502\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 17s 275us/step - loss: 43.2023 - val_loss: 42.5000\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 16s 258us/step - loss: 42.2843 - val_loss: 41.6992\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 15s 248us/step - loss: 41.6015 - val_loss: 41.0960\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 15s 256us/step - loss: 41.0744 - val_loss: 40.6064\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 15s 253us/step - loss: 40.6657 - val_loss: 40.2411\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 15s 256us/step - loss: 40.3346 - val_loss: 39.9483\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 15s 246us/step - loss: 40.0464 - val_loss: 39.7864\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 15s 255us/step - loss: 39.8110 - val_loss: 39.5362\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 15s 249us/step - loss: 39.5869 - val_loss: 39.3554\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 15s 253us/step - loss: 39.3888 - val_loss: 39.2607\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 15s 249us/step - loss: 39.2123 - val_loss: 39.1155\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 15s 250us/step - loss: 39.0129 - val_loss: 38.9619\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 15s 253us/step - loss: 38.8672 - val_loss: 38.7181\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 16s 275us/step - loss: 38.6926 - val_loss: 38.6114\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 16s 270us/step - loss: 38.5634 - val_loss: 38.4693\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 17s 276us/step - loss: 38.4357 - val_loss: 38.4302\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 16s 272us/step - loss: 38.3050 - val_loss: 38.3436\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 16s 272us/step - loss: 38.2143 - val_loss: 38.2428\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 16s 271us/step - loss: 38.0825 - val_loss: 38.2808\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 16s 274us/step - loss: 37.9876 - val_loss: 38.0928\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 16s 274us/step - loss: 37.8710 - val_loss: 38.0176\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 16s 274us/step - loss: 37.7892 - val_loss: 38.0530\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 17s 279us/step - loss: 37.7034 - val_loss: 38.1439\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 17s 278us/step - loss: 37.6212 - val_loss: 37.9024\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 17s 276us/step - loss: 37.5460 - val_loss: 37.8439\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 17s 278us/step - loss: 37.4747 - val_loss: 37.7655\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 15s 257us/step - loss: 37.4109 - val_loss: 37.7753\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 17s 288us/step - loss: 37.3016 - val_loss: 37.6804\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 17s 287us/step - loss: 37.2441 - val_loss: 37.7326\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 17s 278us/step - loss: 37.2041 - val_loss: 37.5837\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 17s 280us/step - loss: 37.1284 - val_loss: 37.5874\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 17s 280us/step - loss: 37.0728 - val_loss: 37.6428\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 17s 277us/step - loss: 36.9999 - val_loss: 37.5795\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 17s 277us/step - loss: 36.9665 - val_loss: 37.5496\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 17s 278us/step - loss: 36.9245 - val_loss: 37.4693\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 17s 281us/step - loss: 36.8681 - val_loss: 37.4455\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 17s 279us/step - loss: 36.8157 - val_loss: 37.4801\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 17s 283us/step - loss: 36.7571 - val_loss: 37.4390\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 17s 285us/step - loss: 36.7157 - val_loss: 37.3746\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 17s 280us/step - loss: 36.6777 - val_loss: 37.2975\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 17s 279us/step - loss: 36.6349 - val_loss: 37.2923\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 17s 281us/step - loss: 36.5771 - val_loss: 37.3786\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 17s 285us/step - loss: 36.5472 - val_loss: 37.3125\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 17s 278us/step - loss: 36.5095 - val_loss: 37.1664\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 17s 283us/step - loss: 36.4568 - val_loss: 37.1642\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 17s 284us/step - loss: 36.4338 - val_loss: 37.2780\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 17s 280us/step - loss: 36.4030 - val_loss: 37.1396\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 17s 284us/step - loss: 36.3661 - val_loss: 37.2826\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 17s 285us/step - loss: 36.3204 - val_loss: 37.1456\n"
     ]
    }
   ],
   "source": [
    "# MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "image_size = x_train.shape[1]\n",
    "original_dim = image_size * image_size\n",
    "x_train = np.reshape(x_train, [-1, original_dim])\n",
    "x_test = np.reshape(x_test, [-1, original_dim])\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255\n",
    "\n",
    "# network parameters\n",
    "input_shape = (original_dim, )\n",
    "intermediate_dim = 512\n",
    "batch_size = 128\n",
    "latent_dim = 2\n",
    "epochs = 50\n",
    "\n",
    "# VAE model = encoder + decoder\n",
    "# build encoder model\n",
    "inputs = Input(shape=input_shape, name='encoder_input')\n",
    "x = Dense(intermediate_dim, activation='relu')(inputs)\n",
    "z_mean = Dense(latent_dim, name='z_mean')(x)\n",
    "z_log_var = Dense(latent_dim, name='z_log_var')(x)\n",
    "\n",
    "# use reparameterization trick to push the sampling out as input\n",
    "# note that \"output_shape\" isn't necessary with the TensorFlow backend\n",
    "z = Lambda(sampling, output_shape=(latent_dim,), name='z')([z_mean, z_log_var])\n",
    "\n",
    "# instantiate encoder model\n",
    "encoder = Model(inputs, [z_mean, z_log_var, z], name='encoder')\n",
    "encoder.summary()\n",
    "plot_model(encoder, to_file='vae_mlp_encoder.png', show_shapes=True)\n",
    "\n",
    "# build decoder model\n",
    "latent_inputs = Input(shape=(latent_dim,), name='z_sampling')\n",
    "x = Dense(intermediate_dim, activation='relu')(latent_inputs)\n",
    "outputs = Dense(original_dim, activation='sigmoid')(x)\n",
    "\n",
    "# instantiate decoder model\n",
    "decoder = Model(latent_inputs, outputs, name='decoder')\n",
    "decoder.summary()\n",
    "plot_model(decoder, to_file='vae_mlp_decoder.png', show_shapes=True)\n",
    "\n",
    "# instantiate VAE model\n",
    "outputs = decoder(encoder(inputs)[2])\n",
    "vae = Model(inputs, outputs, name='vae_mlp')\n",
    "\n",
    "\n",
    "models = (encoder, decoder)\n",
    "data = (x_test, y_test)\n",
    "\n",
    "# VAE loss = mse_loss or xent_loss + kl_loss\n",
    "#if args.mse:\n",
    "reconstruction_loss = mse(inputs, outputs)\n",
    "\n",
    "\n",
    "reconstruction_loss *= original_dim\n",
    "kl_loss = 1 + z_log_var - K.square(z_mean) - K.exp(z_log_var)\n",
    "kl_loss = K.sum(kl_loss, axis=-1)\n",
    "kl_loss *= -0.5\n",
    "vae_loss = K.mean(reconstruction_loss + kl_loss)\n",
    "vae.add_loss(vae_loss)\n",
    "vae.compile(optimizer='adam')\n",
    "vae.summary()\n",
    "plot_model(vae,\n",
    "           to_file='vae_mlp.png',\n",
    "           show_shapes=True)\n",
    "\n",
    "\n",
    "    # train the autoencoder\n",
    "vae.fit(x_train,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(x_test, None))\n",
    "vae.save_weights('vae_mlp_mnist.h5')\n",
    "\n",
    "plot_results(models,\n",
    "         data,\n",
    "         batch_size=batch_size,\n",
    "         model_name=\"vae_mlp\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
