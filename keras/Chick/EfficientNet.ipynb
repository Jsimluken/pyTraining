{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#!pip install -U efficientnet\n",
    "#!pip install scikit-image\n",
    "from efficientnet import EfficientNetB0\n",
    "from keras.layers import GlobalAveragePooling2D, Dense, Dropout, Input, Conv2D\n",
    "from keras.models import Model\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.datasets import fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.legacy import interfaces\n",
    "import keras.backend as K\n",
    "from keras.optimizers import Optimizer\n",
    "\n",
    "class Adam_lr_mult(Optimizer):\n",
    "    \"\"\"Adam optimizer.\n",
    "    Adam optimizer, with learning rate multipliers built on Keras implementation\n",
    "    # Arguments\n",
    "        lr: float >= 0. Learning rate.\n",
    "        beta_1: float, 0 < beta < 1. Generally close to 1.\n",
    "        beta_2: float, 0 < beta < 1. Generally close to 1.\n",
    "        epsilon: float >= 0. Fuzz factor. If `None`, defaults to `K.epsilon()`.\n",
    "        decay: float >= 0. Learning rate decay over each update.\n",
    "        amsgrad: boolean. Whether to apply the AMSGrad variant of this\n",
    "            algorithm from the paper \"On the Convergence of Adam and\n",
    "            Beyond\".\n",
    "    # References\n",
    "        - [Adam - A Method for Stochastic Optimization](http://arxiv.org/abs/1412.6980v8)\n",
    "        - [On the Convergence of Adam and Beyond](https://openreview.net/forum?id=ryQu7f-RZ)\n",
    "        \n",
    "    AUTHOR: Erik Brorson\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, lr=0.001, beta_1=0.9, beta_2=0.999,\n",
    "                 epsilon=None, decay=0., amsgrad=False,\n",
    "                 multipliers=None, debug_verbose=False,**kwargs):\n",
    "        super(Adam_lr_mult, self).__init__(**kwargs)\n",
    "        with K.name_scope(self.__class__.__name__):\n",
    "            self.iterations = K.variable(0, dtype='int64', name='iterations')\n",
    "            self.lr = K.variable(lr, name='lr')\n",
    "            self.beta_1 = K.variable(beta_1, name='beta_1')\n",
    "            self.beta_2 = K.variable(beta_2, name='beta_2')\n",
    "            self.decay = K.variable(decay, name='decay')\n",
    "        if epsilon is None:\n",
    "            epsilon = K.epsilon()\n",
    "        self.epsilon = epsilon\n",
    "        self.initial_decay = decay\n",
    "        self.amsgrad = amsgrad\n",
    "        self.multipliers = multipliers\n",
    "        self.debug_verbose = debug_verbose\n",
    "\n",
    "    @interfaces.legacy_get_updates_support\n",
    "    def get_updates(self, loss, params):\n",
    "        grads = self.get_gradients(loss, params)\n",
    "        self.updates = [K.update_add(self.iterations, 1)]\n",
    "\n",
    "        lr = self.lr\n",
    "        if self.initial_decay > 0:\n",
    "            lr *= (1. / (1. + self.decay * K.cast(self.iterations,\n",
    "                                                  K.dtype(self.decay))))\n",
    "\n",
    "        t = K.cast(self.iterations, K.floatx()) + 1\n",
    "        lr_t = lr * (K.sqrt(1. - K.pow(self.beta_2, t)) /\n",
    "                     (1. - K.pow(self.beta_1, t)))\n",
    "\n",
    "        ms = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n",
    "        vs = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n",
    "        if self.amsgrad:\n",
    "            vhats = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n",
    "        else:\n",
    "            vhats = [K.zeros(1) for _ in params]\n",
    "        self.weights = [self.iterations] + ms + vs + vhats\n",
    "\n",
    "        for p, g, m, v, vhat in zip(params, grads, ms, vs, vhats):\n",
    "\n",
    "            # Learning rate multipliers\n",
    "            if self.multipliers:\n",
    "                multiplier = [mult for mult in self.multipliers if mult in p.name]\n",
    "            else:\n",
    "                multiplier = None\n",
    "            if multiplier:\n",
    "                new_lr_t = lr_t * self.multipliers[multiplier[0]]\n",
    "                if self.debug_verbose:\n",
    "                    print('Setting {} to learning rate {}'.format(multiplier[0], new_lr_t))\n",
    "                    print(K.get_value(new_lr_t))\n",
    "            else:\n",
    "                new_lr_t = lr_t\n",
    "                if self.debug_verbose:\n",
    "                    print('No change in learning rate {}'.format(p.name))\n",
    "                    print(K.get_value(new_lr_t))\n",
    "            m_t = (self.beta_1 * m) + (1. - self.beta_1) * g\n",
    "            v_t = (self.beta_2 * v) + (1. - self.beta_2) * K.square(g)\n",
    "            if self.amsgrad:\n",
    "                vhat_t = K.maximum(vhat, v_t)\n",
    "                p_t = p - new_lr_t * m_t / (K.sqrt(vhat_t) + self.epsilon)\n",
    "                self.updates.append(K.update(vhat, vhat_t))\n",
    "            else:\n",
    "                p_t = p - new_lr_t * m_t / (K.sqrt(v_t) + self.epsilon)\n",
    "\n",
    "            self.updates.append(K.update(m, m_t))\n",
    "            self.updates.append(K.update(v, v_t))\n",
    "            new_p = p_t\n",
    "\n",
    "            # Apply constraints.\n",
    "            if getattr(p, 'constraint', None) is not None:\n",
    "                new_p = p.constraint(new_p)\n",
    "\n",
    "            self.updates.append(K.update(p, new_p))\n",
    "        return self.updates\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {'lr': float(K.get_value(self.lr)),\n",
    "                  'beta_1': float(K.get_value(self.beta_1)),\n",
    "                  'beta_2': float(K.get_value(self.beta_2)),\n",
    "                  'decay': float(K.get_value(self.decay)),\n",
    "                  'epsilon': self.epsilon,\n",
    "                  'amsgrad': self.amsgrad,\n",
    "                  'multipliers':self.multipliers}\n",
    "        base_config = super(Adam_lr_mult, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-b9dd465ef724>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0mclass_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-b9dd465ef724>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epochs, batch_size, input_shape, class_count)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;31m#正規化\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mx_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0mx_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def prepare_new_model(input_shape, class_count):\n",
    "    # 学習済みモデルの取り出し\n",
    "    feature_extractor = EfficientNetB0(input_shape=input_shape, weights='imagenet', include_top=False)\n",
    "    # 犬猫分類器を引っ付ける\n",
    "    x = feature_extractor.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(rate=0.25)(x)\n",
    "    x = Dense(class_count, activation='sigmoid')(x)\n",
    "    # 新たなモデルの定義\n",
    "    model = Model(inputs=feature_extractor.input, outputs=x)\n",
    "    print(model.summary())\n",
    "    return model\n",
    "  \n",
    "def changeChannle(image):\n",
    "    input_ = Input((28,28,1))\n",
    "    conv2d = Conv2D(3, 1, use_bias=False,name=\"conv2d\")\n",
    "    out1 = conv2d(input_)\n",
    "    out1.trainable = False\n",
    "    model1=Model(input_, out1)\n",
    "    print(model1.summary())\n",
    "    model1.layers[1].set_weights([np.ones(([1, 1, 1, 3]))/3])\n",
    "    \n",
    "    res = model1.predict(image)\n",
    "    return res\n",
    "     \n",
    "    \n",
    "def get_adam_for_fine_tuning(lr, decay, multiplier, model):\n",
    "    lr_multiplier = {}\n",
    "    # 自分が引っ付けたレイヤーの学習係数は1、学習済みの部分は小さな値を設定する\n",
    "    for layer in model.layers:\n",
    "        if 'dense' in layer.name:\n",
    "            lr_multiplier[layer.name] = 1.0\n",
    "        else:\n",
    "            lr_multiplier[layer.name] = multiplier\n",
    "    return Adam_lr_mult(lr=lr, decay=decay, multipliers=lr_multiplier)\n",
    "\n",
    "def train(epochs, batch_size, input_shape, class_count):\n",
    "    #画像を一次元化\n",
    "    (x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "    x_train = x_train.reshape(60000, 28, 28, 1)\n",
    "    x_test = x_test.reshape(10000, 28, 28, 1)\n",
    "\n",
    "    #正規化\n",
    "    x_train = x_train.astype('float32')/255\n",
    "    x_test = x_test.astype('float32')/255\n",
    "    \n",
    "    x_train = changeChannle(x_train)\n",
    "    x_test = changeChannle(x_test)\n",
    "    \n",
    "    #正解ラベルをone-hot-encoding\n",
    "    y_train = to_categorical(y_train, 10)\n",
    "    y_test = to_categorical(y_test, 10)\n",
    "    \n",
    "    \n",
    "    # モデルの生成\n",
    "    model = prepare_new_model(input_shape, class_count)\n",
    "    # ファインチューニング用Adamオプティマイザ\n",
    "    optimizer = get_adam_for_fine_tuning(lr=1e-3, decay=1e-5, multiplier=0.01, model=model)\n",
    "    # コンパイルして\n",
    "    model.compile(optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    # fit_generatorするだけ\n",
    "    \n",
    "    h = model.fit(x_train, y_train,\n",
    "         batch_size=batch_size,\n",
    "         epochs=epochs,\n",
    "         verbose=1)\n",
    "\n",
    "    score = model.evaluate(x_test, y_test)\n",
    "    print(score[0])\n",
    "    print(score[1])\n",
    "    # 学習データ、検証データのロスとAccをファイルに出力\n",
    "    with open('loss.csv', 'a') as f:\n",
    "        for loss_t, acc_t, loss_v, acc_v in zip(h.history['loss'], h.history['acc'], h.history['val_loss'], h.history['val_acc']):\n",
    "            f.write(str(loss_t) + ',' + str(acc_t) + ',' + str(loss_v) + ',' + str(acc_v) + '\\n')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    epochs = 5\n",
    "    batch_size = 128\n",
    "    input_shape = (28, 28, 3)\n",
    "    class_count = 10\n",
    "    train(epochs, batch_size, input_shape, class_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.layers import GlobalAveragePooling2D, Dense, Dropout, Input, Conv2D\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = np.zeros(([10, 28, 28, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 28, 28, 1)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(image):\n",
    "    input_ = Input((28,28,1))\n",
    "    conv2d = Conv2D(3, 1, use_bias=False,name=\"conv2d\")\n",
    "    out1 = conv2d(input_)\n",
    "    out1.trainable = False\n",
    "    model1=Model(input_, out1)\n",
    "    print(model1.summary())\n",
    "    model1.layers[1].set_weights([np.ones(([1, 1, 1, 3]))/3])\n",
    "    \n",
    "    res = model1.predict(image)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_15 (InputLayer)        (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 28, 28, 3)         3         \n",
      "=================================================================\n",
      "Total params: 3\n",
      "Trainable params: 3\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[[ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.],\n",
       "         ..., \n",
       "         [ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.]],\n",
       "\n",
       "        [[ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.],\n",
       "         ..., \n",
       "         [ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.]],\n",
       "\n",
       "        [[ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.],\n",
       "         ..., \n",
       "         [ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.]],\n",
       "\n",
       "        ..., \n",
       "        [[ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.],\n",
       "         ..., \n",
       "         [ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.]],\n",
       "\n",
       "        [[ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.],\n",
       "         ..., \n",
       "         [ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.]],\n",
       "\n",
       "        [[ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.],\n",
       "         ..., \n",
       "         [ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.]]],\n",
       "\n",
       "\n",
       "       [[[ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.],\n",
       "         ..., \n",
       "         [ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.]],\n",
       "\n",
       "        [[ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.],\n",
       "         ..., \n",
       "         [ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.]],\n",
       "\n",
       "        [[ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.],\n",
       "         ..., \n",
       "         [ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.]],\n",
       "\n",
       "        ..., \n",
       "        [[ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.],\n",
       "         ..., \n",
       "         [ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.]],\n",
       "\n",
       "        [[ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.],\n",
       "         ..., \n",
       "         [ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.]],\n",
       "\n",
       "        [[ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.],\n",
       "         ..., \n",
       "         [ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.]]],\n",
       "\n",
       "\n",
       "       [[[ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.],\n",
       "         ..., \n",
       "         [ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.]],\n",
       "\n",
       "        [[ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.],\n",
       "         ..., \n",
       "         [ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.]],\n",
       "\n",
       "        [[ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.],\n",
       "         ..., \n",
       "         [ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.]],\n",
       "\n",
       "        ..., \n",
       "        [[ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.],\n",
       "         ..., \n",
       "         [ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.]],\n",
       "\n",
       "        [[ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.],\n",
       "         ..., \n",
       "         [ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.]],\n",
       "\n",
       "        [[ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.],\n",
       "         ..., \n",
       "         [ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.]]],\n",
       "\n",
       "\n",
       "       ..., \n",
       "       [[[ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.],\n",
       "         ..., \n",
       "         [ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.]],\n",
       "\n",
       "        [[ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.],\n",
       "         ..., \n",
       "         [ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.]],\n",
       "\n",
       "        [[ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.],\n",
       "         ..., \n",
       "         [ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.]],\n",
       "\n",
       "        ..., \n",
       "        [[ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.],\n",
       "         ..., \n",
       "         [ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.]],\n",
       "\n",
       "        [[ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.],\n",
       "         ..., \n",
       "         [ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.]],\n",
       "\n",
       "        [[ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.],\n",
       "         ..., \n",
       "         [ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.]]],\n",
       "\n",
       "\n",
       "       [[[ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.],\n",
       "         ..., \n",
       "         [ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.]],\n",
       "\n",
       "        [[ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.],\n",
       "         ..., \n",
       "         [ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.]],\n",
       "\n",
       "        [[ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.],\n",
       "         ..., \n",
       "         [ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.]],\n",
       "\n",
       "        ..., \n",
       "        [[ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.],\n",
       "         ..., \n",
       "         [ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.]],\n",
       "\n",
       "        [[ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.],\n",
       "         ..., \n",
       "         [ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.]],\n",
       "\n",
       "        [[ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.],\n",
       "         ..., \n",
       "         [ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.]]],\n",
       "\n",
       "\n",
       "       [[[ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.],\n",
       "         ..., \n",
       "         [ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.]],\n",
       "\n",
       "        [[ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.],\n",
       "         ..., \n",
       "         [ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.]],\n",
       "\n",
       "        [[ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.],\n",
       "         ..., \n",
       "         [ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.]],\n",
       "\n",
       "        ..., \n",
       "        [[ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.],\n",
       "         ..., \n",
       "         [ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.]],\n",
       "\n",
       "        [[ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.],\n",
       "         ..., \n",
       "         [ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.]],\n",
       "\n",
       "        [[ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.],\n",
       "         ..., \n",
       "         [ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.]]]], dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
