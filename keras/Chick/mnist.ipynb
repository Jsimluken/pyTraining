{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.7239 - acc: 0.7447 - mean_absolute_error: 0.0731\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 0.4730 - acc: 0.8309 - mean_absolute_error: 0.0492\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.4288 - acc: 0.8449 - mean_absolute_error: 0.0446\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.4020 - acc: 0.8549 - mean_absolute_error: 0.0420\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.3857 - acc: 0.8606 - mean_absolute_error: 0.0405\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.3738 - acc: 0.8645 - mean_absolute_error: 0.0393\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.3629 - acc: 0.8672 - mean_absolute_error: 0.0382\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.3536 - acc: 0.8705 - mean_absolute_error: 0.0372\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.3443 - acc: 0.8723 - mean_absolute_error: 0.0364\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.3382 - acc: 0.8754 - mean_absolute_error: 0.0357\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.3330 - acc: 0.8776 - mean_absolute_error: 0.0354\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.3286 - acc: 0.8788 - mean_absolute_error: 0.0348\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.3247 - acc: 0.8809 - mean_absolute_error: 0.0344\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.3186 - acc: 0.8823 - mean_absolute_error: 0.0338\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.3164 - acc: 0.8837 - mean_absolute_error: 0.0336\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.3084 - acc: 0.8856 - mean_absolute_error: 0.0329\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.3092 - acc: 0.8847 - mean_absolute_error: 0.0329\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.3027 - acc: 0.8878 - mean_absolute_error: 0.0323\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.2994 - acc: 0.8885 - mean_absolute_error: 0.0320\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 3s 48us/step - loss: 0.3007 - acc: 0.8882 - mean_absolute_error: 0.0322\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.2972 - acc: 0.8882 - mean_absolute_error: 0.0317\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 0.2951 - acc: 0.8906 - mean_absolute_error: 0.0316\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.2909 - acc: 0.8919 - mean_absolute_error: 0.0310\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.2890 - acc: 0.8916 - mean_absolute_error: 0.0310\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.2884 - acc: 0.8934 - mean_absolute_error: 0.0308\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.2841 - acc: 0.8944 - mean_absolute_error: 0.0306\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.2823 - acc: 0.8929 - mean_absolute_error: 0.0304\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.2798 - acc: 0.8955 - mean_absolute_error: 0.0300\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.2763 - acc: 0.8980 - mean_absolute_error: 0.0297\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.2784 - acc: 0.8954 - mean_absolute_error: 0.0299\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.2776 - acc: 0.8969 - mean_absolute_error: 0.0297\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.2737 - acc: 0.8975 - mean_absolute_error: 0.0295\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.2750 - acc: 0.8975 - mean_absolute_error: 0.0295\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.2709 - acc: 0.8993 - mean_absolute_error: 0.0293\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.2688 - acc: 0.9002 - mean_absolute_error: 0.0289\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.2673 - acc: 0.8999 - mean_absolute_error: 0.0287\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.2631 - acc: 0.9019 - mean_absolute_error: 0.0283\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.2647 - acc: 0.9013 - mean_absolute_error: 0.0284\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.2649 - acc: 0.9012 - mean_absolute_error: 0.0284\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.2601 - acc: 0.9027 - mean_absolute_error: 0.0280\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.2615 - acc: 0.9019 - mean_absolute_error: 0.0282\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.2580 - acc: 0.9035 - mean_absolute_error: 0.0277\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.2613 - acc: 0.9020 - mean_absolute_error: 0.0280\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.2551 - acc: 0.9050 - mean_absolute_error: 0.0275\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.2562 - acc: 0.9043 - mean_absolute_error: 0.0276\n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.2524 - acc: 0.9047 - mean_absolute_error: 0.0274\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.2535 - acc: 0.9055 - mean_absolute_error: 0.0273\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.2548 - acc: 0.9043 - mean_absolute_error: 0.0275\n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.2509 - acc: 0.9056 - mean_absolute_error: 0.0271\n",
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.2520 - acc: 0.9058 - mean_absolute_error: 0.0272\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.2517 - acc: 0.9058 - mean_absolute_error: 0.0272\n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.2483 - acc: 0.9057 - mean_absolute_error: 0.0267\n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.2497 - acc: 0.9064 - mean_absolute_error: 0.0271\n",
      "Epoch 54/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.2513 - acc: 0.9057 - mean_absolute_error: 0.0271\n",
      "Epoch 55/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.2437 - acc: 0.9092 - mean_absolute_error: 0.0264\n",
      "Epoch 56/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.2471 - acc: 0.9073 - mean_absolute_error: 0.0266\n",
      "Epoch 57/100\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 0.2443 - acc: 0.9087 - mean_absolute_error: 0.0264\n",
      "Epoch 58/100\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.2438 - acc: 0.9089 - mean_absolute_error: 0.0263\n",
      "Epoch 59/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.2430 - acc: 0.9084 - mean_absolute_error: 0.0262\n",
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.2390 - acc: 0.9114 - mean_absolute_error: 0.0259\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 2s 40us/step - loss: 0.2423 - acc: 0.9087 - mean_absolute_error: 0.0261\n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.2418 - acc: 0.9093 - mean_absolute_error: 0.0262\n",
      "Epoch 63/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.2416 - acc: 0.9100 - mean_absolute_error: 0.0261\n",
      "Epoch 64/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.2391 - acc: 0.9106 - mean_absolute_error: 0.0258\n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.2405 - acc: 0.9088 - mean_absolute_error: 0.0260\n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.2420 - acc: 0.9093 - mean_absolute_error: 0.0259\n",
      "Epoch 67/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.2364 - acc: 0.9124 - mean_absolute_error: 0.0256\n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.2367 - acc: 0.9108 - mean_absolute_error: 0.0256\n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.2335 - acc: 0.9115 - mean_absolute_error: 0.0254\n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.2354 - acc: 0.9118 - mean_absolute_error: 0.0255\n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.2341 - acc: 0.9113 - mean_absolute_error: 0.0253\n",
      "Epoch 72/100\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.2344 - acc: 0.9119 - mean_absolute_error: 0.0254\n",
      "Epoch 73/100\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 0.2332 - acc: 0.9119 - mean_absolute_error: 0.0253\n",
      "Epoch 74/100\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 0.2302 - acc: 0.9136 - mean_absolute_error: 0.0249\n",
      "Epoch 75/100\n",
      "60000/60000 [==============================] - 3s 48us/step - loss: 0.2292 - acc: 0.9133 - mean_absolute_error: 0.0249\n",
      "Epoch 76/100\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.2306 - acc: 0.9141 - mean_absolute_error: 0.0249\n",
      "Epoch 77/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.2303 - acc: 0.9129 - mean_absolute_error: 0.0250\n",
      "Epoch 78/100\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 0.2317 - acc: 0.9128 - mean_absolute_error: 0.0250\n",
      "Epoch 79/100\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.2283 - acc: 0.9143 - mean_absolute_error: 0.0247\n",
      "Epoch 80/100\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.2285 - acc: 0.9140 - mean_absolute_error: 0.0247\n",
      "Epoch 81/100\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.2226 - acc: 0.9159 - mean_absolute_error: 0.0243\n",
      "Epoch 82/100\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.2271 - acc: 0.9149 - mean_absolute_error: 0.0246\n",
      "Epoch 83/100\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.2234 - acc: 0.9159 - mean_absolute_error: 0.0242\n",
      "Epoch 84/100\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.2274 - acc: 0.9141 - mean_absolute_error: 0.0246\n",
      "Epoch 85/100\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 0.2225 - acc: 0.9161 - mean_absolute_error: 0.0241\n",
      "Epoch 86/100\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.2254 - acc: 0.9146 - mean_absolute_error: 0.0243\n",
      "Epoch 87/100\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 0.2249 - acc: 0.9145 - mean_absolute_error: 0.0244\n",
      "Epoch 88/100\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.2231 - acc: 0.9171 - mean_absolute_error: 0.0242\n",
      "Epoch 89/100\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.2229 - acc: 0.9150 - mean_absolute_error: 0.0242\n",
      "Epoch 90/100\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.2212 - acc: 0.9163 - mean_absolute_error: 0.0240\n",
      "Epoch 91/100\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 0.2203 - acc: 0.9175 - mean_absolute_error: 0.0240\n",
      "Epoch 92/100\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.2204 - acc: 0.9162 - mean_absolute_error: 0.0239\n",
      "Epoch 93/100\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 0.2255 - acc: 0.9147 - mean_absolute_error: 0.0244\n",
      "Epoch 94/100\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.2208 - acc: 0.9179 - mean_absolute_error: 0.0239\n",
      "Epoch 95/100\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 0.2159 - acc: 0.9191 - mean_absolute_error: 0.0235\n",
      "Epoch 96/100\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 0.2185 - acc: 0.9178 - mean_absolute_error: 0.0237\n",
      "Epoch 97/100\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.2192 - acc: 0.9176 - mean_absolute_error: 0.0238\n",
      "Epoch 98/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.2206 - acc: 0.9158 - mean_absolute_error: 0.0239\n",
      "Epoch 99/100\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.2193 - acc: 0.9166 - mean_absolute_error: 0.0237\n",
      "Epoch 100/100\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.2141 - acc: 0.9194 - mean_absolute_error: 0.0234\n",
      "10000/10000 [==============================] - 0s 45us/step\n",
      "0.357231965518\n",
      "0.8862\n"
     ]
    }
   ],
   "source": [
    "# https://qiita.com/wataoka/items/5c6766d3e1c674d61425\n",
    "#sequencial\n",
    "\n",
    "from keras.datasets import fashion_mnist\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "#画像を一次元化\n",
    "\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "\n",
    "#正規化\n",
    "x_train = x_train.astype('float32')/255\n",
    "x_test = x_test.astype('float32')/255\n",
    "\n",
    "#正解ラベルをone-hot-encoding\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)\n",
    "\n",
    "# make sequential model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_dim=784))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "#最適化、損失関数（学習で最小化したいメトリクス）、評価メトリックス\n",
    "model.compile(optimizer=Adam(),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy', 'mae'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "         batch_size=100,\n",
    "         epochs=100,\n",
    "         verbose=1)\n",
    "\n",
    "score = model.evaluate(x_test, y_test)\n",
    "print(score[0])\n",
    "print(score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "#funcional\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "#画像を一元化\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "\n",
    "#正規化\n",
    "x_train = x_train.astype('float32')/255\n",
    "x_test = x_test.astype('float32')/255\n",
    "\n",
    "#one-hot\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test,10)\n",
    "\n",
    "#make functional model\n",
    "\n",
    "input_ = Input(shape=(784,))\n",
    "layer1 = Dense(64, activation='relu')(input_)\n",
    "layer1 = Dense(64, activation='relu')(layer1)\n",
    "layer1 = Dense(10, activation='softmax')(layer1)\n",
    "\n",
    "model = Model(inputs = input_, outputs=layer1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 17s 278us/step - loss: 0.2493 - acc: 0.9296 - mean_absolute_error: 0.0206\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 16s 273us/step - loss: 0.1583 - acc: 0.9607 - mean_absolute_error: 0.0098\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 16s 270us/step - loss: 0.1471 - acc: 0.9666 - mean_absolute_error: 0.0079\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 16s 269us/step - loss: 0.1368 - acc: 0.9712 - mean_absolute_error: 0.0068\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 17s 276us/step - loss: 0.1369 - acc: 0.9729 - mean_absolute_error: 0.0061\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 17s 278us/step - loss: 0.1375 - acc: 0.9738 - mean_absolute_error: 0.0058\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 17s 279us/step - loss: 0.1373 - acc: 0.9758 - mean_absolute_error: 0.0054\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 17s 280us/step - loss: 0.1372 - acc: 0.9768 - mean_absolute_error: 0.0051\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 17s 286us/step - loss: 0.1315 - acc: 0.9781 - mean_absolute_error: 0.0047\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 17s 284us/step - loss: 0.1281 - acc: 0.9802 - mean_absolute_error: 0.0044\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 17s 282us/step - loss: 0.1311 - acc: 0.9805 - mean_absolute_error: 0.0042\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 17s 284us/step - loss: 0.1261 - acc: 0.9813 - mean_absolute_error: 0.0040\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0fedf63860>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile('rmsprop',\n",
    "              'categorical_crossentropy',\n",
    "             ['accuracy', 'mae'])\n",
    "\n",
    "model.fit(x_train, y_train, 100, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 33us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.24401600380304145, 0.97009999999999996, 0.0063132683433211479]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 6s 92us/step - loss: 0.7912 - acc: 0.7332 - mean_absolute_error: 0.0789\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.5205 - acc: 0.8209 - mean_absolute_error: 0.0530\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.4698 - acc: 0.8360 - mean_absolute_error: 0.0478\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.4397 - acc: 0.8451 - mean_absolute_error: 0.0450\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.4217 - acc: 0.8530 - mean_absolute_error: 0.0431\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.4078 - acc: 0.8577 - mean_absolute_error: 0.0417\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 4s 62us/step - loss: 0.3877 - acc: 0.8629 - mean_absolute_error: 0.0400\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.3836 - acc: 0.8643 - mean_absolute_error: 0.0394\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.3743 - acc: 0.8673 - mean_absolute_error: 0.0385\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.3677 - acc: 0.8706 - mean_absolute_error: 0.0379\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 4s 58us/step - loss: 0.3589 - acc: 0.8736 - mean_absolute_error: 0.0370\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 4s 62us/step - loss: 0.3535 - acc: 0.8746 - mean_absolute_error: 0.0365\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.3466 - acc: 0.8773 - mean_absolute_error: 0.0357\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 4s 66us/step - loss: 0.3440 - acc: 0.8785 - mean_absolute_error: 0.0356\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.3405 - acc: 0.8803 - mean_absolute_error: 0.0352\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 4s 62us/step - loss: 0.3358 - acc: 0.8809 - mean_absolute_error: 0.0347\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.3321 - acc: 0.8823 - mean_absolute_error: 0.0344\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.3293 - acc: 0.8835 - mean_absolute_error: 0.0341\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.3232 - acc: 0.8843 - mean_absolute_error: 0.0336\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.3173 - acc: 0.8860 - mean_absolute_error: 0.0332\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.3175 - acc: 0.8866 - mean_absolute_error: 0.0330\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.3115 - acc: 0.8889 - mean_absolute_error: 0.0326\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.3129 - acc: 0.8876 - mean_absolute_error: 0.0326\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.3085 - acc: 0.8897 - mean_absolute_error: 0.0322\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.3077 - acc: 0.8899 - mean_absolute_error: 0.0320\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.3055 - acc: 0.8907 - mean_absolute_error: 0.0318\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.2991 - acc: 0.8924 - mean_absolute_error: 0.0314\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.2966 - acc: 0.8932 - mean_absolute_error: 0.0310\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.3003 - acc: 0.8922 - mean_absolute_error: 0.0313\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.2938 - acc: 0.8949 - mean_absolute_error: 0.0306\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.2976 - acc: 0.8942 - mean_absolute_error: 0.0310\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.2873 - acc: 0.8970 - mean_absolute_error: 0.0301\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.2944 - acc: 0.8936 - mean_absolute_error: 0.0307\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.2882 - acc: 0.8966 - mean_absolute_error: 0.0302\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.2853 - acc: 0.8976 - mean_absolute_error: 0.0298\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.2833 - acc: 0.8978 - mean_absolute_error: 0.0297\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.2840 - acc: 0.8985 - mean_absolute_error: 0.0296\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.2845 - acc: 0.8988 - mean_absolute_error: 0.0296\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.2826 - acc: 0.8991 - mean_absolute_error: 0.0295\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.2804 - acc: 0.8992 - mean_absolute_error: 0.0293\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.2780 - acc: 0.8987 - mean_absolute_error: 0.0293\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.2753 - acc: 0.9013 - mean_absolute_error: 0.0289\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 4s 62us/step - loss: 0.2757 - acc: 0.9020 - mean_absolute_error: 0.0288\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.2708 - acc: 0.9023 - mean_absolute_error: 0.0286\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.2786 - acc: 0.8993 - mean_absolute_error: 0.0291\n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.2731 - acc: 0.9010 - mean_absolute_error: 0.0288\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.2701 - acc: 0.9037 - mean_absolute_error: 0.0283\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.2702 - acc: 0.9036 - mean_absolute_error: 0.0283\n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.2686 - acc: 0.9042 - mean_absolute_error: 0.0281\n",
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.2657 - acc: 0.9051 - mean_absolute_error: 0.0281\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.2668 - acc: 0.9047 - mean_absolute_error: 0.0279\n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.2651 - acc: 0.9051 - mean_absolute_error: 0.0278\n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 4s 62us/step - loss: 0.2664 - acc: 0.9051 - mean_absolute_error: 0.0278\n",
      "Epoch 54/100\n",
      "60000/60000 [==============================] - 4s 67us/step - loss: 0.2617 - acc: 0.9063 - mean_absolute_error: 0.0275\n",
      "Epoch 55/100\n",
      "60000/60000 [==============================] - 4s 67us/step - loss: 0.2619 - acc: 0.9054 - mean_absolute_error: 0.0276\n",
      "Epoch 56/100\n",
      "60000/60000 [==============================] - 4s 67us/step - loss: 0.2593 - acc: 0.9062 - mean_absolute_error: 0.0271\n",
      "Epoch 57/100\n",
      "60000/60000 [==============================] - 4s 67us/step - loss: 0.2635 - acc: 0.9059 - mean_absolute_error: 0.0276\n",
      "Epoch 58/100\n",
      "60000/60000 [==============================] - 4s 67us/step - loss: 0.2590 - acc: 0.9080 - mean_absolute_error: 0.0273\n",
      "Epoch 59/100\n",
      "60000/60000 [==============================] - 4s 67us/step - loss: 0.2609 - acc: 0.9063 - mean_absolute_error: 0.0274\n",
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 4s 67us/step - loss: 0.2594 - acc: 0.9065 - mean_absolute_error: 0.0272\n",
      "Epoch 61/100\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.2587 - acc: 0.9061 - mean_absolute_error: 0.0272\n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.2562 - acc: 0.9073 - mean_absolute_error: 0.0269\n",
      "Epoch 63/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.2562 - acc: 0.9073 - mean_absolute_error: 0.0271\n",
      "Epoch 64/100\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.2565 - acc: 0.9092 - mean_absolute_error: 0.0269\n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.2562 - acc: 0.9090 - mean_absolute_error: 0.0268\n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.2549 - acc: 0.9094 - mean_absolute_error: 0.0267\n",
      "Epoch 67/100\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.2505 - acc: 0.9093 - mean_absolute_error: 0.0264\n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.2554 - acc: 0.9085 - mean_absolute_error: 0.0267\n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 4s 66us/step - loss: 0.2509 - acc: 0.9113 - mean_absolute_error: 0.0263\n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - 4s 62us/step - loss: 0.2503 - acc: 0.9096 - mean_absolute_error: 0.0264\n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 4s 62us/step - loss: 0.2511 - acc: 0.9096 - mean_absolute_error: 0.0265\n",
      "Epoch 72/100\n",
      "60000/60000 [==============================] - 4s 62us/step - loss: 0.2510 - acc: 0.9108 - mean_absolute_error: 0.0263\n",
      "Epoch 73/100\n",
      "60000/60000 [==============================] - 4s 64us/step - loss: 0.2506 - acc: 0.9104 - mean_absolute_error: 0.0263\n",
      "Epoch 74/100\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.2508 - acc: 0.9098 - mean_absolute_error: 0.0264\n",
      "Epoch 75/100\n",
      "60000/60000 [==============================] - 4s 62us/step - loss: 0.2476 - acc: 0.9103 - mean_absolute_error: 0.0263\n",
      "Epoch 76/100\n",
      "60000/60000 [==============================] - 4s 62us/step - loss: 0.2465 - acc: 0.9114 - mean_absolute_error: 0.0259\n",
      "Epoch 77/100\n",
      "60000/60000 [==============================] - 4s 62us/step - loss: 0.2483 - acc: 0.9116 - mean_absolute_error: 0.0259\n",
      "Epoch 78/100\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.2472 - acc: 0.9122 - mean_absolute_error: 0.0259\n",
      "Epoch 79/100\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.2471 - acc: 0.9123 - mean_absolute_error: 0.0259\n",
      "Epoch 80/100\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.2456 - acc: 0.9117 - mean_absolute_error: 0.0258\n",
      "Epoch 81/100\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.2446 - acc: 0.9118 - mean_absolute_error: 0.0257\n",
      "Epoch 82/100\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.2435 - acc: 0.9128 - mean_absolute_error: 0.0256\n",
      "Epoch 83/100\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.2461 - acc: 0.9111 - mean_absolute_error: 0.0259\n",
      "Epoch 84/100\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.2409 - acc: 0.9138 - mean_absolute_error: 0.0253\n",
      "Epoch 85/100\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.2413 - acc: 0.9135 - mean_absolute_error: 0.0253\n",
      "Epoch 86/100\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.2417 - acc: 0.9137 - mean_absolute_error: 0.0254\n",
      "Epoch 87/100\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.2402 - acc: 0.9142 - mean_absolute_error: 0.0254\n",
      "Epoch 88/100\n",
      "60000/60000 [==============================] - 4s 64us/step - loss: 0.2410 - acc: 0.9131 - mean_absolute_error: 0.0254\n",
      "Epoch 89/100\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.2386 - acc: 0.9143 - mean_absolute_error: 0.0253\n",
      "Epoch 90/100\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.2398 - acc: 0.9140 - mean_absolute_error: 0.0252\n",
      "Epoch 91/100\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.2368 - acc: 0.9152 - mean_absolute_error: 0.0249\n",
      "Epoch 92/100\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.2379 - acc: 0.9146 - mean_absolute_error: 0.0250\n",
      "Epoch 93/100\n",
      "60000/60000 [==============================] - 4s 72us/step - loss: 0.2379 - acc: 0.9139 - mean_absolute_error: 0.0252\n",
      "Epoch 94/100\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.2395 - acc: 0.9136 - mean_absolute_error: 0.0252\n",
      "Epoch 95/100\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.2375 - acc: 0.9168 - mean_absolute_error: 0.0248\n",
      "Epoch 96/100\n",
      "60000/60000 [==============================] - 4s 64us/step - loss: 0.2361 - acc: 0.9164 - mean_absolute_error: 0.0249\n",
      "Epoch 97/100\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.2328 - acc: 0.9174 - mean_absolute_error: 0.0245\n",
      "Epoch 98/100\n",
      "60000/60000 [==============================] - 4s 66us/step - loss: 0.2344 - acc: 0.9163 - mean_absolute_error: 0.0246\n",
      "Epoch 99/100\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.2359 - acc: 0.9163 - mean_absolute_error: 0.0247\n",
      "Epoch 100/100\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.2324 - acc: 0.9172 - mean_absolute_error: 0.0245\n",
      "10000/10000 [==============================] - 1s 94us/step\n",
      "0.368894147778\n",
      "0.8773\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'fit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-9107f7f9d4f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0maxR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'upper right'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m \u001b[0mplot_history_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0mplot_history_acc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./mnist-tutorial.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'fit' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# https://qiita.com/wataoka/items/5c6766d3e1c674d61425\n",
    "#sequencial\n",
    "#BN\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.datasets import fashion_mnist\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "#画像を一次元化\n",
    "\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "\n",
    "#正規化\n",
    "x_train = x_train.astype('float32')/255\n",
    "x_test = x_test.astype('float32')/255\n",
    "\n",
    "#正解ラベルをone-hot-encoding\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)\n",
    "\n",
    "# make sequential model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, BatchNormalization, Activation\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=784))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(64))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(64))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "#最適化、損失関数（学習で最小化したいメトリクス）、評価メトリックス\n",
    "model.compile(optimizer=Adam(),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy', 'mae'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "         batch_size=128,\n",
    "         epochs=100,\n",
    "         verbose=1)\n",
    "\n",
    "score = model.evaluate(x_test, y_test)\n",
    "print(score[0])\n",
    "print(score[1])\n",
    "\n",
    "\n",
    "# ----------------------------------------------\n",
    "# Some plots\n",
    "# ----------------------------------------------\n",
    "fig, (axL, axR) = plt.subplots(ncols=2, figsize=(10,4))\n",
    "\n",
    "# loss\n",
    "def plot_history_loss(fit):\n",
    "    # Plot the loss in the history\n",
    "    axL.plot(fit.history['loss'],label=\"loss for training\")\n",
    "    axL.plot(fit.history['val_loss'],label=\"loss for validation\")\n",
    "    axL.set_title('model loss')\n",
    "    axL.set_xlabel('epoch')\n",
    "    axL.set_ylabel('loss')\n",
    "    axL.legend(loc='upper right')\n",
    "\n",
    "# acc\n",
    "def plot_history_acc(fit):\n",
    "    # Plot the loss in the history\n",
    "    axR.plot(fit.history['acc'],label=\"loss for training\")\n",
    "    axR.plot(fit.history['val_acc'],label=\"loss for validation\")\n",
    "    axR.set_title('model accuracy')\n",
    "    axR.set_xlabel('epoch')\n",
    "    axR.set_ylabel('accuracy')\n",
    "    axR.legend(loc='upper right')\n",
    "\n",
    "plot_history_loss(fit)\n",
    "plot_history_acc(fit)\n",
    "fig.savefig('./mnist-tutorial.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://qiita.com/wataoka/items/5c6766d3e1c674d61425\n",
    "#sequencial\n",
    "#CNN\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.datasets import fashion_mnist\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "from keras.utils.np_utils import to_categorical\n",
    "# make sequential model\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D,BatchNormalization, Activation\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "\n",
    "# ----------------------------------------------\n",
    "# Some plots\n",
    "# ----------------------------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-4a6fc6e1a469>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m#正解ラベルをone-hot-encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/utils/np_utils.py\u001b[0m in \u001b[0;36mto_categorical\u001b[0;34m(y, num_classes, dtype)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mis\u001b[0m \u001b[0mplaced\u001b[0m \u001b[0mlast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \"\"\"\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'int'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "#画像を一次元化\n",
    "\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "\n",
    "#正規化\n",
    "x_train = x_train.astype('float32')/255\n",
    "x_test = x_test.astype('float32')/255\n",
    "\n",
    "#正解ラベルをone-hot-encoding\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=(28, 28, 1)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "\n",
    "#最適化、損失関数（学習で最小化したいメトリクス）、評価メトリックス\n",
    "model.compile(optimizer=Adam(),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy', 'mae'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "         batch_size=128,\n",
    "         epochs=100,\n",
    "         verbose=1,\n",
    "         validation_data=(x_test, y_test))\n",
    "\n",
    "score = model.evaluate(x_test, y_test)\n",
    "print(score[0])\n",
    "print(score[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
