{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn,reshape\n",
    "import torchvision\n",
    "from torch.nn import functional as F\n",
    "from torchvision.datasets import mnist\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import transforms\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        self.fc1 = nn.Linear(784,256)\n",
    "        self.fc2 = nn.Linear(256,128)\n",
    "        self.fc3 = nn.Linear(128,10)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = reshape(x,(-1,784))\n",
    "        h = F.sigmoid(self.fc1(x))\n",
    "        h = F.sigmoid(self.fc2(h))\n",
    "        h = F.softmax(self.fc3(h))\n",
    "        return h\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.parameters of Net(\n",
       "  (fc1): Linear(in_features=784, out_features=256, bias=True)\n",
       "  (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (fc3): Linear(in_features=128, out_features=10, bias=True)\n",
       ")>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Split: train\n",
       "    Root Location: ./data\n",
       "    Transforms (if any): Compose(\n",
       "                             ToTensor()\n",
       "                             Normalize(mean=(0.5,), std=(0.5,))\n",
       "                         )\n",
       "    Target Transforms (if any): None"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "[transforms.ToTensor(),transforms.Normalize((0.5,),(0.5,))]\n",
    "    )\n",
    "trainset = torchvision.datasets.MNIST(root='./data', \n",
    "                                        train=True,\n",
    "                                        download=True,\n",
    "                                      transform=transform\n",
    "                                        )\n",
    "trainset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(\n",
    "    trainset,\n",
    "    batch_size=512,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, [tensor([[[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "            [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "            [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "            ...,\n",
       "            [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "            [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "            [-1., -1., -1.,  ..., -1., -1., -1.]]],\n",
       "  \n",
       "  \n",
       "          [[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "            [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "            [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "            ...,\n",
       "            [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "            [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "            [-1., -1., -1.,  ..., -1., -1., -1.]]],\n",
       "  \n",
       "  \n",
       "          [[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "            [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "            [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "            ...,\n",
       "            [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "            [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "            [-1., -1., -1.,  ..., -1., -1., -1.]]],\n",
       "  \n",
       "  \n",
       "          ...,\n",
       "  \n",
       "  \n",
       "          [[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "            [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "            [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "            ...,\n",
       "            [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "            [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "            [-1., -1., -1.,  ..., -1., -1., -1.]]],\n",
       "  \n",
       "  \n",
       "          [[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "            [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "            [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "            ...,\n",
       "            [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "            [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "            [-1., -1., -1.,  ..., -1., -1., -1.]]],\n",
       "  \n",
       "  \n",
       "          [[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "            [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "            [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "            ...,\n",
       "            [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "            [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "            [-1., -1., -1.,  ..., -1., -1., -1.]]]]),\n",
       "  tensor([7, 1, 2, 1, 5, 8, 9, 3, 9, 6, 0, 6, 2, 0, 0, 2, 5, 8, 2, 1, 9, 4, 1, 4,\n",
       "          7, 2, 8, 5, 5, 0, 5, 1, 0, 9, 5, 7, 5, 3, 6, 9, 1, 0, 1, 3, 3, 3, 6, 9,\n",
       "          1, 3, 3, 0, 8, 3, 1, 8, 9, 4, 3, 6, 7, 1, 8, 8, 4, 3, 6, 4, 5, 0, 8, 3,\n",
       "          3, 8, 9, 5, 9, 1, 4, 5, 3, 6, 1, 4, 2, 9, 3, 5, 2, 4, 4, 3, 9, 3, 9, 2,\n",
       "          6, 0, 7, 6, 5, 1, 7, 8, 5, 6, 1, 7, 4, 8, 4, 6, 6, 6, 5, 8, 6, 7, 5, 4,\n",
       "          4, 2, 5, 7, 3, 7, 1, 8, 2, 0, 0, 2, 4, 0, 7, 3, 2, 6, 0, 4, 8, 9, 4, 1,\n",
       "          6, 4, 3, 3, 9, 6, 3, 2, 6, 6, 5, 1, 0, 1, 2, 7, 8, 7, 9, 3, 1, 9, 3, 9,\n",
       "          8, 5, 2, 2, 4, 3, 9, 5, 3, 3, 0, 1, 4, 2, 2, 6, 4, 6, 9, 3, 4, 3, 1, 1,\n",
       "          1, 7, 5, 7, 0, 0, 1, 2, 0, 0, 6, 1, 1, 1, 3, 1, 6, 6, 7, 7, 2, 6, 4, 3,\n",
       "          4, 2, 1, 9, 0, 5, 9, 7, 2, 1, 4, 0, 4, 1, 0, 6, 0, 6, 0, 6, 8, 9, 2, 2,\n",
       "          9, 6, 1, 0, 0, 2, 4, 2, 1, 2, 3, 5, 5, 1, 3, 7, 8, 2, 8, 3, 9, 0, 4, 3,\n",
       "          0, 7, 5, 7, 4, 9, 3, 9, 7, 0, 0, 4, 6, 8, 5, 4, 5, 0, 5, 5, 3, 3, 4, 0,\n",
       "          2, 9, 5, 2, 6, 2, 8, 8, 5, 8, 0, 2, 2, 9, 9, 7, 8, 2, 6, 1, 5, 1, 1, 8,\n",
       "          1, 2, 7, 7, 6, 1, 1, 1, 7, 8, 9, 6, 0, 6, 3, 0, 7, 2, 5, 1, 2, 8, 7, 7,\n",
       "          1, 7, 4, 7, 4, 7, 5, 9, 8, 1, 2, 3, 5, 7, 9, 5, 0, 7, 2, 7, 7, 7, 9, 8,\n",
       "          4, 3, 4, 1, 1, 5, 8, 2, 6, 7, 9, 3, 7, 7, 0, 0, 2, 0, 4, 8, 5, 5, 0, 5,\n",
       "          3, 8, 3, 9, 3, 2, 9, 7, 6, 8, 7, 9, 9, 2, 6, 4, 8, 4, 3, 5, 3, 5, 0, 9,\n",
       "          3, 9, 7, 5, 5, 0, 6, 5, 1, 8, 9, 4, 0, 8, 9, 0, 9, 1, 8, 3, 7, 1, 1, 1,\n",
       "          9, 1, 3, 7, 5, 3, 2, 0, 4, 0, 2, 0, 1, 5, 4, 9, 4, 3, 2, 3, 0, 8, 3, 1,\n",
       "          1, 6, 9, 2, 6, 7, 5, 1, 5, 9, 9, 0, 0, 4, 7, 7, 3, 6, 5, 8, 6, 9, 3, 1,\n",
       "          7, 8, 3, 1, 7, 2, 3, 3, 1, 5, 5, 9, 6, 9, 2, 1, 6, 2, 8, 5, 7, 8, 4, 2,\n",
       "          7, 5, 7, 7, 9, 4, 4, 8])])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enumerate(trainloader,0).__next__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 10000\n",
       "    Split: test\n",
       "    Root Location: ./data\n",
       "    Transforms (if any): None\n",
       "    Target Transforms (if any): None"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset = torchvision.datasets.MNIST(root='./data', \n",
    "                                        train=False, \n",
    "                                        download=True, \n",
    "                                        )\n",
    "testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jsimluken/.pyenv/versions/miniconda3-latest/lib/python3.6/site-packages/torch/nn/functional.py:1332: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/Users/jsimluken/.pyenv/versions/miniconda3-latest/lib/python3.6/site-packages/ipykernel_launcher.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:1.5136831998825073\n",
      "loss:1.4871243238449097\n",
      "loss:1.5279425382614136\n",
      "loss:1.488146424293518\n",
      "loss:1.502821445465088\n",
      "loss:1.5049352645874023\n",
      "loss:1.4769048690795898\n",
      "loss:1.4957000017166138\n",
      "loss:1.4748421907424927\n",
      "loss:1.463855266571045\n"
     ]
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "    for i ,(input_,label) in enumerate(trainloader,0):\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(net(input_),label)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"loss:{loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jsimluken/.pyenv/versions/miniconda3-latest/lib/python3.6/site-packages/ipykernel_launcher.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "out = net(input_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.5059, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion(out,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.estimator import "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
